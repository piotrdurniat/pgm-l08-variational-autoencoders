{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42e06d42",
   "metadata": {},
   "source": [
    "Przed oddaniem zadania upewnij się, że wszystko działa poprawnie.\n",
    "**Uruchom ponownie kernel** (z paska menu: Kernel$\\rightarrow$Restart) a następnie\n",
    "**wykonaj wszystkie komórki** (z paska menu: Cell$\\rightarrow$Run All).\n",
    "\n",
    "Upewnij się, że wypełniłeś wszystkie pola `TU WPISZ KOD` lub `TU WPISZ ODPOWIEDŹ`, oraz\n",
    "że podałeś swoje imię i nazwisko poniżej:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834a74c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e425e07",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {
    "image-2.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPEAAADxCAYAAAAay1EJAAAABHNCSVQICAgIfAhkiAAAIABJREFUeF7tXQnQF8WxH07BA+RQLomcoiSpokQfARU/8Ywnh4goRPNKRSMKMV5FVL5AFC9ERQ0SEpUbD4iRQ0AKkCcpRKVSefVEQBBEQI2Acsgl+/o3fvtl2W+P2d3Z67/dVQvff2emp6dnentmuqenmmBQ4cAvmjVrdk3NmjXP3r9//wnff/99w6ZNm36zdu3a1iqFOY8/B9q3b79h27ZtjerWrbv9qKOO+urQoUP/s3Xr1hlU8n3/0sXOUa3Yzfdsff2jjz76vmrVqt3eunVrcdNNNx3Xrl27aiTMwnw8S3NiYA6Q0Ao8W7ZsEZ9++qkxfvz4XRs3bjQInt+7d+8oQrg7MFIuUEwONGjQ4Ik6derse+WVV/aQdsAgYkiJAyTUxksvvbSndu3a+6lfHivmiORWK3Pg/PPP73raaad9Vl5evj+lMcvVenBg+PDh+6l/NlxyySVnKndqATLydLqik+krP6B+/fovrFu37rgaNWoUoOvz2cQDBw6INm3a7Kbp9S07duyYls9W6KWahZj4ecEFF1xGCmDKO++8U18vexlbXBwoKyv7ljbBrnv77bfnxlVHXvBWzwuhcdEJDcwCHBd348O7ZMmS+mQpmEr91z++WvKBueiauGPLli3f27Rp0/H56C6m0s6B5s2bf0ebX1gjr7GnFeV3oTVxq1atZm7YsIEFOMejff369fWoH9/McRMik15YIT7mmGMeGzhw4Em8iRV5DKWKgEyBon///i2PO+64h1MlJMXKizqdrk+d/yV5Xh2VIu+5ao0cIC+vg7Rz3YBQ7tGINheoCqmJGzZs+OCECRNYgHMxRNWI/POf/1yrUaNGD6rlLq1chdTENJX+ltz66jVp0qS0erPArfniiy8EOYLs3LVrF7RxoaCImvgX5At9mAW4tMZ5ixYtBD0Yz2eUVsv8W1M4IaYNkKvoMAPvSPuPjdzloH6tR153PXNHeESCCyfE5OVzDp1Gisg2Lp5FDqBfaYPrnCzSFidNhRPigwcPNsVRQobS4wCm1IcPH25eei3zblERhbgxC7H3oMhrKnlviX379jXOK/1h6S6cEFNH72AhDjtcsl0OQkzPzmxTqZ+6IpqYcGJVPycZYyY4QJFYQEehxnVNGtBl1Gg8WYUl1DFLskpcFuiiWF/i/fffFx9++KFYvXq1gCvi8uXLxe7du8WZZ54pVq5cKY499ljRrVs3TDdhTxWnn3666NKli+BNPu8ezIN81KQmlNEz3LspqacuSZ2CjBFAZ58FnsmTJwuKBSauvfZaQSeyxIUXXiiFlHbhpeCSY4vYs2ePFGhyMxUff/yxfD755BNBEUykUA8YMECW69GjR8ZamQlyyoiKbMsHfWnKPSKiZCGpXHNXZqFNoWgg32Bj1KhRBkXaNCiQgfHqq68amzdvDoXLLPT5558b06dPN0iADdorMB599FGDIk1GwplmYRorWtdK1JbMy0fhNrY0fxASQzdy5EipVWvVqiVWrVolFi5cKPr27QsvpUg0nHTSSaJfv35i0aJFcjqONSXZWsXDDxf2UFAkfqZRmIU4Da4HqHPq1KlyukwRLATiS/3ud78TpIkDYFDPil37e++9V5AmFuTZJp8ZMxD6mSHLHEhEiAcNGiRee+21LPMhk7SRG6GYM2eO+Oabb8TgwYMTpfHOO++UMaBnzZolbr755kTr5sqCcSARIaa1m9wNZVDjAHaaKw67iylTpshNqjQAG2O0XhbXXHONnMp/8MEHaZDBdfpwALvTsQId+ZP427ZtG2s9pYL89ddfl9r322+/lWvTLAB2rr/++mtx6623it69e4uePQt3xiAL3eBKQ+xCDDPIGWcU7nSYK8O9EmbPni3XoFlcemBdPnHiRNGrVy85S6AA7l5N4bQEOZCIEJM5JMEm5bMqCDBsvlkUYCtHsUbG9JoOGohLL700n8wuMapjXxNDE7MQe48aTKHp3ie5/swDYI+DwuGIv/3tb3kgN3M0wpSHzV5YHGDSw1LzxRdfDE1nrEJM12yInTt3is6dO4cmsNQLYhMLWjjrGtjeD9DIM2fO5M0uO2N8fkN4sbzcvn279LjD/7fccovcb4DdPxTE6ZECjyLalY7qwFMeqmHuhaLSo7U8bV4Z5PqoFWdSyMiV06Bd66SqU6qHuj2zHluQBdAHrzg7kCDLtHHjxtmT/H6Xx6qJeSrt/iVBimkHzsoutDe1VVNhdoI2hnZh8OYAdvg/+ugjqXXvu+++Kpmvvvpq+e7xxx+vkub3goXYj0MxpcMTCwcS6DrVmGpIBu1FF10kl0xYJzM4cwAfOSg0us3Rde1rWnDoRgtcsO6MyO0t6epYHLxpri+nB/g/IpS70R7yfURy9BQnBw6DrufUgyxlLN99951BLpopU/Fj9RhzIceFYzHCGkk+MD2uoMlYsGCBJ4/MfE7TbY+C8U2nzS8PduAYjuQADjNg2pSWJ5bu/oCP9YgRI8QjjzyiG3Wu8WFjFxtWAFhoMKVWgcCzmqhfGrcvBBbqeDRAuUrDA+TRQFJ4FDhOSCeRwiOoKEmXoVd+4antkf4+/vjjDXKpjEwTmUsMsh9HxhMFQQUvAgwH76xES2hNjOOiZt+o8Bf9gPw07Q7CgnJtzh44Ggfti8U7fGyxTgLgHfym8SXiDRAhRo8eLehMsPfIUUg1+euUFfymq2oEDYojkrHeQv/YAbjsee15VH7TNFA8+eST4p577lHJXtJ5THlAIzH2VcysZp/C7BQIonxpsN6lo2sGviB4oHlhVsJXh4gwoC2wDkAe/EYepAeE8kAN8s8csHq92XGgn04HRUYKvoKn5oOvt9+ayzRxWMvh74BrMFfaEWCAzie7pieRUNE2/1GgmINoDqWJrbz26xeTL9Z+CcCrchGWSHPBDsG027ZAtN0+DIGnbXQ56PB/gA2vckV+q2YLwB+9WenrLCNy6AB8DM1OV5l+mXZI60DB37roMdtUVlZmLF68WEcTQ+GoaJ/qWPDNR0QEFmLrBxbyoQL25ZFKmYo8wafTWKxjeoBpGaZtmC7bN6+c7MPIA68kTCvgZoipHdzPigTgC+yEOsA65cI01gvA9/Hjx1fJgil04E2UKliOfIElE6aSJMw+OUs32WrrVe1vp2WOMoeCfGnwtcCXhZB7fsGhhd2mzdYvDqbZClCu3Bi1jApVxpOFQulEjollUoYpMPrB70tv/8KjjPmobLYE5cRnn31mnHzyyUGLactf0Ta1kaCQiwgLpInNpWRQHptLTpRTmVlZGKZuYoIGhkEai29oYHxt3QBfFbdDD3D2tnqnAG8RAGFlcZwvakwsk1emJvY75okTR04A7a2y2eJU1usdCbCoXr262LBhg1e2kk2zzngw01HlsVUTo1wQUPbYMgUYyL2mYBBueKbYp9hWoqwC7oUrSEOynhcHHRBWVheYO5ngtRtgaus0TQP/nVz/3PAEfd+/f3+xYsWKoMVKIr91PLspMqeGWqOmePWpU1klIcZgwBoWgC+4V5QOp/WwvWIrkchfBMD63+vDFpQHGCAIaue25nJbB4P3cX84oUmcPh5B25i3/Ohjq+nPbRZkbxfcLK3l/GZX9vK+QowKzCkCOsfvC64ixFYivOyddmKz/NtreQG6cTPDqaeeqq0JOLb22GOPOU7X0GduAwgCrPNj4tQgtBPt9YJS/HjbNw9VNbGdF1iuBgFfIb7//vsr8Vn/dqvEaz1slikVwbXyAOt8uFHC2cEJENIGNzMkAW4CTKZAR6HXTVPHjh1F7dq1HdFi5xanttxodCyUk5d2YYTDDQ79+z2ma6bZzKCa2NdjC+YgE9ymbmY6phN+62HkNafm+DvoIr6SmIz98cwzz4g77rhDDB8+XDz00EPSl/juu++upBJ3IyXhK+22DsZHJimPOWzgob1WgPCCN9j0goCDX6UE2KC1jmtoU5UPFTYorSYpFfmpwjevLfSgDgUwe6j4S8PBgAiRj4K3UHkVoqO90GbOsCNq3LhxZbtoIBs4qfTEE08Y8JfG4Xkcoo8TrP1l8hf/e5ksYNqASdDusBOFzl27dhkU7la2m6b8Bs1CDPDDpOnEE0+Mgt6zbEUd0UaIpbSXfFgJsXvQuZlY7cTbTYCKZlcrmnJPjy2r7UpVOFWItw4wNMILaCaw2JJ/uIW/+NscGIHe00VilVXibxOPjvekaSrxAS8id9DhfwOeTHGCfTBYeexlDzbdA3UKMdqJ9t5www1SgK202PljTcvi3xh/Kv1m2u3NNviNaxOn9agiynr1lQsd3kJsddVT+UKACD93Squ2sLtmuhJJiDWCSzXRX9s1MQYwTZWM/fv3x66JoW2dhMBPOE3nHVX/XhUumeeLTU2MD1mpa2LTpRh94OeAY+Vh2HIWHOrOHn62K6yHsb712/m0ugj6uQtqFNzYUb388svymlCsB7GJhWtDEbkDJ3qwBsRtCrheNA6wmgCt+P3WwWYgQ5TBJowuoOm0vMcJl7/BDAa+YD2MDS3wB1etTpo0SVd1mcBjXQ8H2Ziybob57Tm5NdRzdzrIppOKaQlmGNN+iO131UPSbsRn6f3QoUPFwYMHjxBeK31nnXWWFGrd4GUP9ougafcu0kUbRSyRF5pbwSrM4BPueiolsFpcVE1LkAdruViE2EqM9UvjxHwVITZ36/BxgLmjlAD2V2gct7O05gXfOtvsZw/2q8s6E/Jy4PHDY0/HJea0hLC/lr8hzEiL2+HEsfIYX1oPpKgqP6vlB7IWtg88NbFVU/p54PgJMZwTzK8O8oYlOMZ+iIQaAeO8ADZiDG6d4Fanij0YU/C47PVop59NvJRmYehTKy/9lp7mGLB+yKIsLT2FGJWZyCF4bocVzPWwm2DCy8v86tAGSiIOBzqFRQcu2A11Cg0+ik6zI691MPrPPA5qnUqrDjpVPuAyuKBeR6q485BPhZ+48cEcD+CV6kEJx/bTLpfvUSvTDAH7rhNgex27bE5g7r5hx051292Gp9yR8PAvnciM/R2dYjLatWunpR67TZJYUbkzjV1q9Jf1wTtzF9qa1/xb0UqgTHurVq0MOsWknF9nxoo2hR8dtpJEm698gH4rf/0sNMhvtSZEtAx4m5hM5oIoU5AhlHYiIdx2UwYIMwmFqcpeJkDHlWvrkR8RBahab1aErkEIm6jg5tThJKAq79w+zmHohPBCiNOCtITYKpR+bbd+hN2Unx8OS7qaEJsFrM4f+Ns0TINx+BvEQSubDQKBIbWvtQ0lI8Tke27QpWkB+id/WSkovvH73/8+NcLTEmKrT4Vf402PRWjvCMrNrCaYEKMUKoXWBSH2KRq0NQTXrpX9GuWTXjJCvGjRIqNHjx4+zc13cvfu3Y2lS5em1oi0hNjqeeXVeKsW1iQnwYXYTiA0r87pmB0//S4ZIUbbmjVrZmzZssWhmfl/tWnTJqNly5apNiQtIba6vXrNPq1LTE2MUvfYIuY4AiISWO3Jjpn4ZSUHhgwZUnLeSmbjcEk6nF6KCLDMmDvybuZY07MO8hLlPuIq/IWmi/JFwJQ6hNN2kCrLqxAd7UWQurXnPXTokFGjRg3teLOAkLoldTJAQ7ThcWTpIPJhTpWdZqbmdFu3JQD0+dqJvRhihhWJZOPyqqAE00iA5VnjsWPHllTrxowZo+VmizwzBQ4s8EiDTwWirsAuDxmBBsbBf7hVxhKmOciXxv6ZNTe47O81/y7X3LGayXNH52UrxXlbnLstBaDBGujkTpxtprGSmiY22wUToGmSxUwVm70xzlaDB4+3ChS+OOY6QLOglQQ6nGRCaBac4CHb6RFtmjBhgrxknExOuW8r2oH2MPzIAXjT4UkKIk2n/fylk2pEVuuBEOOIYuvWrcWvf/1rQYHVK0nt16+fPK4HN9Q8w7x58wSdoxZ9+vTJczPyTTtNAUJtbJlb6nFOjSpwl2vmcAIk/6cKRLcg+iufG2+88QiXRByWp/O1idKkqzLykTbq1aunC50WPBW81jZkiKhQ8qGlMWpIwm9sYRudp9L+YwXa2Ap2zUyOEeK2227zR5TBHLfffrsA/QzpciD0dBr24bCHmNNtcrK1Yy1M2rhKpaYwP//88+Lss88WvXr1qpInyy+uuOIKgSVBp06dskxmMWjLw3RBc0+oTVI05po4caJj/CtqV+X7K6+80qDNEI21xoeK1r++dyHHV7s35gqeahsyeZCP0JpYG5cKgAi2Qi+ApkYcZlovZ14jQwPD7llqh/q9+ifrab7B47PegKzTh4PfboHSIbxYM5vmJ/xPESLFr371K/GnP/1JUKzqzDSPIlgKrIFZgDPTJZWEsBDH3CdPP/10lYgeduG1ktCzZ09B545FkyZNxMyZM4VbCJ6YyT4CPcxIuNERm1i8Bk6S82p18XRajU/KuejQv3j33XdlfrsWhvDi3l5satmdP6wVIOQpwtu+8cYbcvMIIWDTANCPcD9vvvmmQMgdFuA0esG/ThZifx4FyvHss8+Kc889V9D1LcLUwqrCa68IJ13gRIGLyYErSYAvNJxUcNcwAu8xZJcDLMQa+wZhaSF4uDTssssuk5pYRfN6kYAwv1iPIpYz8OLyrc2bN3sVCZ2GWcSoUaOkqyjW5nDgZ0+s0OxMrCALsUZWI5Ikpr6YguJ6T2hPr2lzkKqHDRsmfvjhBynIXbt2Feedd570u964cWMQNFXywhV02rRpcvaAAPe4rYLMKr73UFdBVKIvaElzbtabxhtbGnsIa1jAgAEDNGL9DypoSFyXimfJkiUCNwjgzmgINqa9CFqOC77xAcF1KfDNxvUx+LDggTZHTGg8WONSPCyJ/LrrrhMjR44UFFonFrpzjHQuLWW+yDr91eirW0ZE4skqLKHBu0QjcfAW0IjuR1SYSkOIoC0hIEmahzBlX7FihbwiZ/Xq1VKb4n5gTMMpTK4gP3dRv359ebUKbl9AYHe4zHbp0kXbTEE7Q0MixIeOQP4TEe6g8u1prMyk/8si4oqz+JI4kWcVt7fLT8hUWv8ao0ePNhDRMitANmjpEYb/iwJor4aB145wrNWAJxEUPJ3WxGZourvuuksTNkaTMgfmUf2/TJkG5ep5Y0uZVZyxIBx4ltqJZ11e2stCnJeeYjqT4AC0L6bSuQqAxtPpJIYG15EXDswlQnVsiiXaXtbEibKbK8swB3K1DrbykYVYw6iClxaOEcKsw5BLDtxJVK+h5+08Us9CrKHXcMrnlVdeEV9++aUGbIwiYQ5gDQyb8JCE69VWHQuxBlZ+8sknEgu8pRhyx4HcTqNNTrMQRxxz8P6CRxQ8hdq3bx8RGxdPmAO5Myc58YeF2IkrAd7RDYeC7leSh/hr1uTN/gCsSztrLs1JTkzjUefElQDvzIDwJ598coBSnDUDHMilOcmJbyzETlwJ8K5Dhw4CV3rWrVs3QCnOmjIHcr8OtvKPhTjiaMIVJtdff31ELFw8QQ7k2pzkxCcWYieu8LtS5QB2HgfTc0opNZCFuJR6k9vixwFMoy/2y5S3dN6dzluPMb1hOYBDDYg26B3JPyz2FMuxEKfIfK46MQ7AnNSWnucSqzHBiliIIzIb9w7jZgSE5GHILAdgTro0s9RFJIyFOCIDZ82aJV544QUZW4shkxwoKXOSE4dZiJ24ovgOLpemBm7QoIFiKc6WIAdKzpzkxDvenXbiiuI7U4Dr1asnfacZMsWBkjQnOXGYhdiJK4rvcF8SAPGdGTLHgZI0JzlxmafTTlxRfGcKMTQxQ6Y4ULLmJCcusyZ24oriO1xBunjxYtbEivxKMFsbqgsH/QsBLMQRuhlXpJSVlUXAwEV1cgAbjRVwmU68WcfF0+ms9xDTp8yBX/4yN/HeldukkpGFWIVLnCfzHMC90DgWWkRgIS5ir5dYm9euXSuee+458cwzz5RYy9Saw2tiNT5xrgxzANPo+fPnZ5jCeEljTRyBv7Nnz5YbW0899VQELFw0CgfuuOMOMXToUNG2Lc43FBNYiCP0+6ZNm8TSpUvFp5+W3Om2CFxJrujcuXPF+vXrxeDBOOdfXODpdIS+R5RLAEe5jMDEkEVhTrr88svF4cOHQ2IonWKsiSP0JQtxBOZFLIp1MG7eYBCChTjCKGAhjsC8CEWxC43bNi6+uOQi7YTiCk+nQ7Htx0IsxBGYF7LomjVr5Plt8+qckGhKqhgLcYTuRKjabt26iVatWkXAwkWDcADT6IULFwYpUvJ5WYgjdDFufeCbHyIwMGBRmJN++9vfijZt2gQsWdrZeU1c2v1bMq1jc5J7V7ImducNp2SEA2xO8u4I1sTe/OHUDHCAzUnencBC7M0fTk2ZA2xO8u8Ank7788g1x7Jly8SiRYtE9+7dRY8ePVzzcUI4DrA5SY1vrInV+OSYa/ny5eIPf/iDWLBggWM6v4zGAZ5Gq/GPhViNT465TJ9p0+nDMRO/DMUBHGq466672JykwD0WYgUmuWVhIXbjTLT3c+bMEZ999pm8HofBnwO8JvbnkWuOo446Sqbt37/fNQ8nBOMATiVdeeWVfC1OALaxJg7ALHvWo48+Wr7au3evPYl/h+TApZdeKuDYwaDOAdbE6ryqkrNz585i+PDh4mc/+1mVNH4RnANsTgrOM5RgIQ7HN1nqpz/9qXwYonOAzUnhechCHJ53XFIjB/h0Unhm8po4PO+4pCYOsDkpGiNZiKPxj0tH5ACbkyIykIrzdDo6DxlDSA6wOSkk42zFWBNH5CM0SVFvHojIOsFulVE5+GN51sQR+XjLLbeILVu2iN69e4uWLVtGxFac4k8//bTo2LGjuOiii4rT6JhaykIckbFNmjSRQvzVV1+xECvyEkHuxo0bJ1avXq1YgrN5cYCF2Is7CmkQYsDWrVsVcnMWcABeWRzsTt9Y4DVxRF42b95cYti8eXNETMUozuYk/f3MQhyRp2a0SxZif0ayOcmfR2Fy8HQ6DNcsZXAfELQx4k8zuHOAzUnuvImawkIckYOnn366wMPgzQE2J3nzJ0oqT6ejcI/LKnGAzUlKbAqdiTVxaNZxQRUOsDlJhUvR8rAQR+Mfl/bhAKbRiAjKEB8HeDodH28Ljxkxsu6++27RunXrwvMiTgawJtbA3U2bNomJEyeK4447TgwZMkQDxvyjgDlp48aN4vnnn89/YzLeAhZiDR20du1a8eCDD4pOnTqlJsQvv/yyqFatmrjhhht8W4S8gBtvvNE3b5gMbE4KwzUuE4QDdD+XXti5c6dBBBjVq1c3Dhw4oBe5IrYdO3YY9evXN+iuZIOEVJYqLy+XdOF/wEsvvSTTkQ/54wI61GDMnz8/LvSeeNHeIIOB8+aTA56DIGxihw4dpMAsXrw4LIrI5Shon6QBD4S1Z8+e8m/8j99mGvLFBWPGjDGGDh0aF3pfvBVtzOfIZKqVOeA7EMJkoCOJUkgeeuihMMW1lDG1sSmsTv/HqYXpVJKBj1maUEQh5t1pZdn3zoiTOQDSxN4ZY0w9/vjjBWlBzxqQjnxxAHtlxcFVxunEgVgUxa5du4xJkyYZdCQxFvyqSL20cZxa+De/+Y1BO9GqZMaWjzqc18ROo77E3sU2gLKC2Lo2rhjUcqof11r4rbfeMuggSCaaX0QhrlZiAqrSHAw2lXy5zUO75YI2ssS3335b2QbSwvKSMt1T6R9++EHgTqqs3AwJMxtBocY1r4lzK6ruhDutjeNaC/M62L0fOCU+DmRi2hc3Eda1sa61cL9+/YyZM2dWkp62OcmJhzRsSnuaFZ9c5AqzU99rf/fqq69qxxkUobk21rUWbtiwoXHCCSdIMrJgTnLiBwtxrmQxNLFOfa/1HTyWMJj+8pe/aMUbFBm0MYUP0uKdtW/fPqNGjRrS22vChAkGHWow1q9fH5Sk2PMXUYgLtQFQIfYYSKG/ACoF//73v4urrrpK/OQnPxHwq65du7ZKsdB5UMf7778vPvzwQxkGtk6dOmL58uVi9+7d4uc//7n417/+JY499lgZQoiEUZx22mkyGkmXLl1Eu3btlOr95z//KcrKygQ2zXAvM8ISDRw4UJx66qnKOJQqipipiBtbLMQRB41bcQjJqlWrxMiRI8UDDzzgli30+3feeUfgmTx5shSqa6+9VjRo0EAKFYS0bt26UnCPOeYYsWfPHinQ33//vfj444/lA2GcNm2aFOoBAwaICy+8UPTo0cOVnhkzZohBgwZV7ngDNz5OuGD9jDPOEMuWLXMtm2RCEYU4Sf5mpa7Yp3SogDShQQPKoIFu0N27WurE4YpRo0YZTZs2NS644AID626KshkJ9+eff25Mnz7dIAE2mjVrZjz66KMGmYuq4MS6GtNp6kT54G8yLRlw8jh48GCV/Gm9qKAvK2ON6YiJA4mNLzoULwc8HYyPXOeIESOMWrVqGU8++WRsXmF0k4Xx2GOPSQH94x//eATNl112WaUAk+Y3SPMb33zzTeR26UbAQhyT1GQMre5x44oPrpiPPPKIa7pKwpQpUwyaGhtjx45Vya4tD10SZ9CUWWppAN0zJemgabexYcMGbfXoRlREIeY1cca+MFZybrrpJrmOpd1gucZNGrCOBg2IWEKnkwRN4WXggywDr4mz3Dv6aNP98deOb8WKFXK9SRtX2nGHQbhgwQIDU+iVK1eGKZ5oGRom8Zoe9I1DxhSBA4kOKqfKyARlnHnmmcb48eMNTLmt8NprrxkUNseAXTZLQDvcBpmUjFmzZmWJrCq0sBBHkIwcFa3S8Um/uOSSSyo3iTDoTjzxRIPsuQbcGK+++uqkyQlUH6KEzJs3L1CZJDOzEOdIEiOQmuSYcq1r6dKlBnavaY0pBbpRo0ZGnz59XPNnKaFv374GRbPMEkmVtLAQR5CMHBXN3ODDFLp3796Zo8uLIGjkLE6tiyjEfBQx5a8P3CVnz54t3njjjZQpCVY9CbCgE03igw8+CFaQc2vnAJuYtLM0GEL4OePwPg7W5w25rnTEAAAMM0lEQVTgztmkSRPp0pkVKKKJiTVxiqMPNljclJBHAQbb4JcNbQyfaob0OMBCnBLvp06dKh05zj///JQo0FMtHbuUhynIj1sPQsYSmAM8nQ7MMj0FcPKIfI9T8cTS04L/YCFbt2jRooX47rvvdKMOjK+I02kW4sDDJHoBHE/EscHBgwdHR5YRDLhIHMcShw0blipFLMSpsj+xymE5Sawye0V0bE+uJelYoT3J93fbtm3F9u3bffNheks3UogXX3yxSl7goIgcrlEvUZYcTgSZvaqU9XtBd1EJRL+sECS/7LGkF1GI+VbEWIaSO9LRo0cLOhPsnsEnBUKmA3ThsdJCZ5EFHZUU99xzjw4SGYciB3g6rcgoXdno4L2M+EEH+wOj/PTTTyvLQAhxqsgujG3atBF0YEFQUDs5ZbcDcHz00UfimmuuqUy69957ZXQOlEW4W7eydlz23xSgQHTt2lVQoAF7UmK/i6iJE2NuhiryckSKNW3hwoUyIocuIEeLI3ywicfyNy538wJE7zDz4oSSTqA4XKneDFnRrgwNNyYlDg7oHLOBcN13330ypI5OGDdunKMg470ToH5TgN3yOJVTfUdxuwza3FLNrj0fC3EcIpM9nNoHjipCMsNEjonlVBdNhx0F2a5lrZobZeIAuipGhslNC1iIsydwcVCUyvhCsLz27dvHVjem6aaGNf+n9a2xbt06WSf+x2+kxX3cMc2Y1EUUYvbYiuMz4YATBx0QVjYuoPW23JiyAja94FGFzSxsXJmbYWHMR0Ho7t+/v6DoJEGKcN4IHGAhjsC8IEUR2N1ptzgIDr+82JW233oImzACxEOAIeRJuEeCBuyAMyTDARbiZPgsb2ZAYPc4AY4cXkKKY4Nxf0jQPrQT7WVIhgMsxMnwWV6tgpsZ4gbc5EC7zo7VeAm4Y4GQLzt27Bj71TUhSeNiJcKB2DaXvBDTuVtj27ZtXlm0ptE1MlU2uqj/DOxQxw0IQo/bJNIAtLFExqlyM1gTK7MqWkYcnMf9RUkAfKbd1qTw8rJ6fsVBD+JU42QTA3MgLg6koSAMeDIlAbANE+PkA88t2syqopHxLm5Iqr32dlS0Pa6xw3gzwgF7vyfym04uGaSNY63L6sxhul7CPmwKtfV/ne6f9kbRuWKDtLH9dSK/WYgzImUxk5HIYLJXEvea2OrMYRdQq3a2CrKfj7W9Daq/v/jiC6N58+aq2bXmYyGOWXoygl7roFFFhpC0cV1ERmeMK6fN2NByAuuhB6sgx+E/TZeex+4V5tRGvCuiEPPGVkJfFvOC7ziqw2YVnDrgzIGLx52ADl/Iw/52uPXWWwW8vXQCLjHfv3+/TpSMy4MDLMQezNGZBBsxBrdugF0YO9HwkoLHlpczB9wtSVNXIQFni3XuWKOdSdjEqzSkoC9YiBPqeAiP/QB/0KohaHjgwgmB7Ny5c6XmhW80tPGOHTtc0SKNLnGr4ppp9bE26/DC41pBRQLiaDt9LPzKcTpzQJUDbsupWN9jnUg+zKHrwLqXGuj7YO3rBm4OIE54o5x0atWqVWzrf7e2me8r2qI6FkoiH8fYSqgbcQiBrisVCGFz0kknRarVfsjBRKaq6d3KB8Xj1Ag6TyxfkyA7JfO7GDjAQhwDU91QDhgwQLz33nuiX79+bllc32Ot++Pmq2sW3wRMw+OGf/zjH+L666+PuxrGb+EAr4kTHA7YhMKatJQBhy9whpkhOQ5wtMvkeC1rIicIuTGFqJelBohyedZZZ4lNmzal1rQiRrtkTZzwcBsyZIiYNGlSwrUmU93kyZPF0KFDk6mMa6nkAGvihAcDbkjALYiHDh1KuOb4q4MWjLpuj0ola+KoHOTyvhyoUaOGGDFihBg7dqxv3jxlGDNmTKSbLfLU1qzRypo4pR7BmdutW7cmdsY4zmbCtEURLj0dTeKs34qbNXFSnOZ6xIQJEwQuGS8FQDvQHoZ0OMAbW+nwXdqKoY3h75xnmDdvnmjcuLHo06dPnpuRa9p5Op1y9+Ga06+//lrg0vG8AS4Vb9mypYCvdFaAp9NZ6YkC0bF06VJx22235bLFt99+uwD9DOlygKfT6fJf3szQq1cv+eQJrrjiCrkk6NSpUyCyERsb2tL64J0f4Dw0ysD91HxMHHHfaOFHG6cnzwG/gzCppNPa0ujbt28qdQetlNa/hv2ytqA47NeyquDDSS7z8jicyHIKv0vDqXAha5MXofRrDDreEss/Z84co2fPnonVF6aiyy+/PLIAo15csWq9zdEeF8yNNggyLoZzAxbi9AUsCQrc+j8T72fNmmUMHDgw9siYQRtLm1cGncIy3nrrraBFHfMjSB80Kf6vEDwDAuoH0NheAf5YiJMQofTr8BsnqaevXLnSQIjb+fPnp04LCJg7d65Rr149Y9WqVdroMQP6WafVXgENzIqhvb0uamchTl/AkqBA20CMGxE0DsW/MhDHOQ2gED0G1r+DBg3SWj00rnX6bEYc8ZommwSgnJfGZiFOQoTSr0PrgIwb2YwZM2QgdvJNjruqI/A/9dRTcu35+uuva68XmtSqdRE2t0L4fNfbbiF5TSKLKMRsYkr/o+JJASJRwqli7969onr16uLxxx+XIX7iAJwHHjVqlDTlHDhwQPpCx+GJhbC6CLNrAmn6yr+9gibgHDZMcgxHcoCFOCcjYtiwYQLHGCHIXbt2Feedd56YPn262LhxY6QWICbWtGnTxLnnnisP9NeuXVseJ4RdNi7APcmI1GkFWjrIn6T5XQ9S2IU/LvryhpfdLvPWYxX0LlmyRAZ9nzJlihTs/v37y1C0uOAb9wPDjRO+2biJETcU4oE2R0xoPHCVnDp1qsR23XXXiYsvvlh07949dm5Au2N2YQ9Yb9WyNNV2/IggvBHuWPaKrV1Et0sW4tiHbfwV0PUwYsWKFTKI/OrVq6U2Xb58uRRcTD8hIBDobt26yZsZENgdcaG7dOmSeFRKeFchPraTpofnlnmThVMwe2hvv2B/RRTi+EdY9mrQvlHDCNU5YNqHnUp4bXCZNmWnctZ3NNwK57FVuDXxKaec8ln2vivFochpPWy2HtNsE+wbXKrr4SL2b+GEeMuWLQ0QUYMheQ5gPdywYUPXirHWNS99s29wqQgx9a2g53jXCko0oXBCXKtWrX+zEKczmlUE8f77768kzqqNycHDc0MLhSDEderU+Xc6rUuv1iIK8VZ0NkPyHFARYmxe4YpWgCnEqvZhutwcxeIxoifPLuUaCyfEdE/wMrrcTJlBnFEfB7zWw9ZaTJsxdqphilIRfpRfs2YNQgEv00cxY8oqB/6LTCw7/XY5OV0vB+z+0l7YrTdA4nZGP39pExdtaiFOUNULmLM6EjXRVThNTHx7n9wLq23btk0TCxmNCgdUtSlw2Te4oJG9HDxQBq6otNfxA/35kQo9pZSniEIMZ4gX7R5DpdSpWWxLECEG/eaUGn9b/azd2rZo0SL0a2nfVufW+IK+P5Y6fL/XlI7T9HIAJ6K8jhA61UYbXPJ0k9f5YbNczZo1D1LeOkUcz4XUxNTRu8nU9NQDDzywp4idnmSbsbOMHWfcEoHdZtiKVcHUxnAR9QI6HLKXfMUfpTz7vPJxWglygG6z/z/yJXZSAvwuIgegPWnIVD7QxOZvlQgeqB6a2+/88O7duw3qx/8tweGp3KQiHoCwMucUuid4JdmN6ylzjDNmigNNmjTZ9dVXXyFu7vpMEZYgMUWdTpssXrNv375b6Wxudq4wSLDz817VOeec8x3NpP67yAKMPiy6EGONNo3uC76eBHln3gd1keiHANMdUNfSuejXi9Rup7YWfTpdyROyQ/anA/QTyOvnaPK/deIVv8sAB/bs2SPIqWMvzaBupDXzaxkgiUnIGAdofJyyjnatD0Tc1+HiMXCAdqEPdOjQYR2NmR+dqzM2eJicDHGgUaNGj5Id+cBf//rXPeQJFMNwZJSqHCDvOoPuPt4DOzDNlh7J0DDJDCk8nXbvimNoeo1zcbfT9Z01b7755mPJ+aBaixYtRPPmzeXDoJcDFeeBBU4j0SEVAx9REuIDhw8ffoHigz1MtbEd2IHlLMQOTHF4dQYJcj96fzaFcm1CA6ph06ZNt9NAa+2Ql1+F4ED79u03kD97Q3La2E6zoC8psue7JNQzCFXhfKGDsu//AXbiAgFdwNCCAAAAAElFTkSuQmCC"
    },
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "60280988",
   "metadata": {},
   "source": [
    "# Autokodery wariacyjne (*Variational Autoencoders*)\n",
    "\n",
    "## Autokoder\n",
    "**Autokoder** (ang. *autoencoder*) to model trenowany w zadaniu rekonstruowania wejścia. Zazwyczaj składa się z dwóch sieci neuronowych:\n",
    "\n",
    "* **kodera** (funkcji $f(\\mathbf{x})$ - kodującego wejście do postaci ukrytej (*latent*) $\\mathbf{h} = f(\\mathbf{x})$,\n",
    "* **dekodera** (funkcji $g(\\mathbf{h})$ - rekonstruującego wejście $\\mathbf{r} = g(\\mathbf{h})$.\n",
    "\n",
    "Innymi słowy, autokoder jest modelem mapującym wejście $\\mathbf{x}$ na wyjście $\\mathbf{r}$ poprzez jego wewnętrzną, ukrytą reprezentację $\\mathbf{h}$.\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "Głównym celem trenowania modelu jest znalezienie najlepszej pary koder-dekoder, która zachowuje maksimum informacji podczas kodowania, co daje najmniejszy **błąd rekonstrukcji** $\\mathcal{L}$:\n",
    "\n",
    "$$(f^*, g^*) = \\arg\\min\\mathcal{L}(\\mathbf{x}, g(f(\\mathbf{x}))).$$\n",
    "\n",
    "W przypadku autokoderów często używaną funkcją kosztu jest błąd średniokwadratowy.\n",
    "\n",
    "Klasyczne autokodery używane są w zwykle w celu redukcji wymiarowości lub wstępnego uczenia cech do modelu. Ze względu na brak wykorzystania etykiet, modele te są trenowane w sposób nienadzorowany.\n",
    "\n",
    "## Autokoder wariacyjny\n",
    "\n",
    "Wykorzystanie wyłącznie błędu rekonstrukcji jako funkcji celu w klasycznych autokoderach wymusza na modelu uczenie się skompresowanej reprezentacji danych, jednak często może prowadzić do jego przetrenowania, przez co jego zdolności generatywne są ograniczone (głównie ze względu na nieregularną przestrzeń ukrytą).\n",
    "\n",
    "Rozwiązaniem pozwalającym na wyuczenie się reprezentacji o wyższej jakości są **autokodery wariacyjne** (ang. *variational autoencoders*). Jest to model generatywny, gdzie zamiast uczenia funkcji kodera mapującej wejście do przestrzeni ukrytej będziemy próbowali uczyć się nieznanego rozkładu danych $p_{\\theta^*}(\\mathbf{z})$.\n",
    "\n",
    "![image-2.png](attachment:image-2.png)\n",
    "\n",
    "Skupmy się na modelu generatywnym $p_\\theta(\\mathbf{z})p_\\theta(\\mathbf{x} | \\mathbf{z})$, oznaczonym liniami ciągłymi. Zakładamy, że przykłady ze zbioru danych $\\mathbf{X} = \\left\\{x^{(i)}\\right\\}_{i=1}^N$, składającego się z $N$ niezależnych i pochodzących z tego samego rozkładu przykładów, generowane są przez proces losowy, w którym występuje nieobserwowana, ciągła zmienna losowa $\\mathbf{z}$. Proces ten składa się z dwóch kroków:\n",
    "\n",
    "1. wektor ukryty $\\mathbf{z}^{(i)}$ generowany jest z rozkładu a priori $p_{\\theta^*}(\\mathbf{z})$,\n",
    "2. obserwacja $\\mathbf{x}^{(i)}$ jest generowana z rozkładu warunkowego $p_{\\theta^*}(\\mathbf{x} | \\mathbf{z})$.\n",
    "\n",
    "Zakładamy tutaj, że rozkłady $p_{\\theta^*}(\\mathbf{z})$ oraz $p_{\\theta^*}(\\mathbf{x} | \\mathbf{z})$ należą do rodzin rozkładów $p_{\\theta}(\\mathbf{z})$ oraz $p_{\\theta}(\\mathbf{x} | \\mathbf{z})$, parametryzowanych przez $\\theta$; zakładamy że ich funkcje gęstości są różniczkowalne względem $\\theta$ i $\\mathbf{z}$. Zależność $\\mathbf{x}^{(i)}$ od $\\mathbf{z}^{(i)}$ będziemy modelować przy użyciu sieci neuronowej o parametrach $\\theta$.\n",
    "\n",
    "Parametry te moglibyśmy znaleźć maksymalizując likelihood:\n",
    "\n",
    "$$p(\\mathbf{x}) = \\int p_\\theta(\\mathbf{x} | \\mathbf{z})p(\\mathbf{z})d\\mathbf{z}.$$\n",
    "\n",
    "Nie jest to jednak możliwe, ze względu na całkowanie po wszystkich wartościach priora. Wprowadzimy zatem model **probabilistycznego kodera** $q_\\phi(\\mathbf{z} | \\mathbf{x})$ (oznaczony linią przerywaną) - aproksymację prawdziwego posteriora $p_\\theta(\\mathbf{z} | \\mathbf{x})$ - rozkład wariacyjny, najczęściej normalny. Będziemy go modelować przy użyciu sieci neuronowej o parametrach $\\phi$. W tym kontekście, model generatywny $p_{\\theta^*}(\\mathbf{x} | \\mathbf{z})$ możemy traktować jako **probabilistyczny dekoder**.\n",
    "\n",
    "Możemy zatem sformułować naszą funkcję celu w następujący sposób:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\log p_\\theta\\left(\\mathbf{x}\\right) & = \\mathbb{E}_{\\mathbf{z} \\sim q_\\phi\\left(\\mathbf{z} | \\mathbf{x}\\right)} \\left[\\log p_\\theta\\left(\\mathbf{x}\\right)\\right] & \\text{$p_\\theta\\left(\\mathbf{x}\\right)$ jest niezależne od $\\mathbf{z}$}\\\\\n",
    "    & = \\mathbb{E}_{\\mathbf{z}}\\left[\\log\\frac{p_\\theta\\left(\\mathbf{x} | \\mathbf{z}\\right)p\\left(\\mathbf{z}\\right)}{p\\left(\\mathbf{z} | \\mathbf{x}\\right)}\\right] & \\text{Reguła Bayesa}\\\\\n",
    "    & = \\mathbb{E}_{\\mathbf{z}}\\left[\\log\\frac{p_\\theta\\left(\\mathbf{x} | \\mathbf{z}\\right)p\\left(\\mathbf{z}\\right)}{p\\left(\\mathbf{z} | \\mathbf{x}\\right)}\\frac{q_\\phi\\left(\\mathbf{z} | \\mathbf{x}\\right)}{q_\\phi\\left(\\mathbf{z} | \\mathbf{x}\\right)}\\right] & \\text{pomnożyć przez 1}\\\\\n",
    "    & = \\mathbb{E}_{\\mathbf{z}}\\left[\\log p_\\theta\\left(\\mathbf{x} | \\mathbf{z}\\right)\\right] - \\mathbb{E}_{\\mathbf{z}}\\left[\\log \\frac{q_\\phi\\left(\\mathbf{z} | \\mathbf{x}\\right)}{p\\left(\\mathbf{z}\\right)}\\right] + \\mathbb{E}_{\\mathbf{z}}\\left[\\log \\frac{q_\\phi\\left(\\mathbf{z} | \\mathbf{x}\\right)}{p\\left(\\mathbf{z} | \\mathbf{x}\\right)}\\right] & \\text{logarytm}\\\\\n",
    "    & = \\underbrace{\\mathbb{E}_{\\mathbf{z}}\\left[\\log p_\\theta\\left(\\mathbf{x} | \\mathbf{z}\\right)\\right] - D_{KL}\\left(q_\\phi\\left(\\mathbf{z} | \\mathbf{x}\\right)\\| p\\left(\\mathbf{z}\\right)\\right)}_{\\mathcal{L}\\left(\\mathbf{x}, \\theta, \\phi\\right)} + \\underbrace{D_{KL}\\left(q_\\phi\\left(\\mathbf{z} | \\mathbf{x}\\right)\\| p\\left(\\mathbf{z} | \\mathbf{x}\\right)\\right)}_{\\ge 0}\\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Dywergencji Kulbacka-Leiblera między prawdziwym posteriorem i jego aproksymacją nie możemy aproksymować wprost, wiemy jednak że jest zawsze większa lub równa zero. Z tą wiedzą możemy przekształcić to równanie do postaci nierówności i uzyskać funkcję kosztu ELBO:\n",
    "\n",
    "$$\\\\log p_\\theta \\left(\\mathbf{x}\\right) \\ge \\underbrace{\\mathbb{E}_{\\mathbf{z}}\\left[\\log p_\\theta\\left(\\mathbf{x} | \\mathbf{z}\\right)\\right]}_{\\text{błąd rekonstrukcji}} - \\underbrace{D_{KL}\\left(q_\\phi\\left(\\mathbf{z} | \\mathbf{x}\\right)\\| p\\left(\\mathbf{z}\\right)\\right)}_{\\text{regularyzacja aproksymacji posteriora}} = \\mathcal{L}\\left(\\mathbf{x}, \\theta, \\phi\\right).$$\n",
    "\n",
    "Musimy zatem jeszcze przyjąć rozkład prior - najczęściej przyjmuje się rozkład standardowy $\\mathcal{N}(0, 1)$.\n",
    "\n",
    "Model ten uczony będzie metodą Maximum Likelihood Estimation:\n",
    "\n",
    "$$\\theta^*, \\phi^* = \\underset{\\theta, \\phi}{\\arg\\max} \\sum_{i=1}^N \\mathcal{L}\\left(x_i, \\theta, \\phi\\right).$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef69871",
   "metadata": {},
   "source": [
    "Zaczniemy od implementacji klasycznego autokodera z wykorzystaniem biblioteki PyTorch. Będziemy się opierać na klasie bazowej `BaseAutoencoder`, której metody należy zaimplementować aby możliwe było wykorzystanie przygotowanych analiz.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8dd1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from IPython.display import Code, display\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from src.ae import BaseAutoEncoder\n",
    "from src.utils import train_ae, AutoEncoderAnalyzer\n",
    "\n",
    "\n",
    "np.random.seed(2021)\n",
    "torch.manual_seed(2021)\n",
    "\n",
    "display(Code(filename=\"src/ae.py\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6067d617",
   "metadata": {},
   "source": [
    "Tworzymy model kodera i dekodera: oba zawierają po jednej warstwie ukrytej oraz odpowiednie funkcje aktywacji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6acc5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"\"\"Encoder module; function h.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_input_features: int,\n",
    "        n_hidden_neurons: int,\n",
    "        n_latent_features: int,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        :param n_input_features: number of input features (28 x 28 = 784 for MNIST)\n",
    "        :param n_hidden_neurons: number of neurons in hidden FC layer\n",
    "        :param n_latent_features: size of the latent vector\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_to_hidden = nn.Linear(n_input_features, n_hidden_neurons)\n",
    "        self.hidden_to_latent = nn.Linear(n_hidden_neurons, n_latent_features)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Encoder forward function.\"\"\"\n",
    "        h = self.input_to_hidden(x)\n",
    "        h = nn.functional.relu(h)\n",
    "        h = self.hidden_to_latent(h)\n",
    "        return h\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    \"\"\"Decoder module; function g.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_latent_features: int,\n",
    "        n_hidden_neurons: int,\n",
    "        n_output_features: int,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        :param n_latent_features: number of latent features (same as in Encoder)\n",
    "        :param n_hidden_neurons: number of neurons in hidden FC layer\n",
    "        :param n_output_features: size of the output vector (28 x 28 = 784 for MNIST)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.latent_to_hidden = nn.Linear(n_latent_features, n_hidden_neurons)\n",
    "        self.hidden_to_output = nn.Linear(n_hidden_neurons, n_output_features)\n",
    "\n",
    "    def forward(self, h: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Decoder forward function.\"\"\"\n",
    "        r = self.latent_to_hidden(h)\n",
    "        r = nn.functional.relu(r)\n",
    "        r = self.hidden_to_output(r)\n",
    "        r = torch.sigmoid(r)\n",
    "        return r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb32e77f",
   "metadata": {},
   "source": [
    "Modele te wykorzystujemy do zaimplementowania Autokodera; implementujemy metody `encoder_forward` oraz `decoder_forward`, które służą do tworzenia ukrytej reprezentacji oraz rekonstruowania na jej podstawie obrazu wejściowego.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0090fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(BaseAutoEncoder):\n",
    "    \"\"\"Auto encoder module.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_data_features: int,\n",
    "        n_encoder_hidden_features: int,\n",
    "        n_decoder_hidden_features: int,\n",
    "        n_latent_features: int,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        :param n_data_features: number of input and output features (28 x 28 = 784 for MNIST)\n",
    "        :param n_encoder_hidden_features: number of neurons in encoder's hidden layer\n",
    "        :param n_decoder_hidden_features: number of neurons in decoder's hidden layer\n",
    "        :param n_latent_features: number of latent features\n",
    "        \"\"\"\n",
    "        encoder = Encoder(\n",
    "            n_input_features=n_data_features,\n",
    "            n_hidden_neurons=n_encoder_hidden_features,\n",
    "            n_latent_features=n_latent_features,\n",
    "        )\n",
    "        decoder = Decoder(\n",
    "            n_latent_features=n_latent_features,\n",
    "            n_hidden_neurons=n_decoder_hidden_features,\n",
    "            n_output_features=n_data_features,\n",
    "        )\n",
    "        super().__init__(\n",
    "            encoder=encoder, decoder=decoder, n_latent_features=n_latent_features\n",
    "        )\n",
    "        self.input_shape = None\n",
    "\n",
    "    def encoder_forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Function to perform forward pass through encoder network.\"\"\"\n",
    "        if self.input_shape is None:\n",
    "            self.input_shape = x.shape[1:]\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        return self.encoder(x)\n",
    "\n",
    "    def decoder_forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Function to perform forward pass through decoder network.\"\"\"\n",
    "        return self.decoder(x).view(-1, *self.input_shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b73e3b8",
   "metadata": {},
   "source": [
    "W zadaniu ponownie wykorzystamy zbiór MNIST, zawierający odręcznie zapisane cyfry w formie obrazów o rozdzielczości $28\\times28$, z wartościami w przedziale $[0, 255]$ (funkcja `ToTensor()` przetransformuje je do zakresu $[0, 1]$). Zbiór treningowy ograniczamy do 10000 przykładów.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbfc980",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MNIST(root=\"data\", download=True, train=True, transform=ToTensor())\n",
    "val_dataset = MNIST(root=\"data\", download=True, train=False, transform=ToTensor())\n",
    "\n",
    "# limiting the dataset\n",
    "indices = np.random.permutation(len(train_dataset.data))[:10_000]\n",
    "train_dataset.data = train_dataset.data[indices]\n",
    "train_dataset.targets = train_dataset.targets[indices]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d7d302",
   "metadata": {},
   "source": [
    "Definiujemy model wraz z arbitralnie dobranymi hiperparametrami oraz funkcję kosztu (MSE). Następnie wywołujemy przygotowaną pętlę uczenia w celu wytrenowania modelu. Parametry dobrane tutaj powinny spowodować przetrenowanie autokodera.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec379e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "lr = 1e-2\n",
    "epochs = 20\n",
    "\n",
    "ae_model = Autoencoder(\n",
    "    n_data_features=28 * 28,  # MNIST pixels\n",
    "    n_encoder_hidden_features=128,  # chosen arbitrarily\n",
    "    n_decoder_hidden_features=128,  # chosen arbitrarily\n",
    "    n_latent_features=10,  # how many features will be used to represent input\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, batch_size=batch_size, shuffle=False, drop_last=False\n",
    ")\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "train_ae(\n",
    "    ae_model,\n",
    "    epochs=epochs,\n",
    "    train_loader=train_dataloader,\n",
    "    val_loader=val_loader,\n",
    "    lr=lr,\n",
    "    loss_fn=loss_fn,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e883f3",
   "metadata": {},
   "source": [
    "Poniżej znajdują się wywołania analiz działania modelu: porównanie rekonstrukcji z obrazami wejściowymi, uśrednione punkty reprezentujące każdą klasę, badanie zdolności generatywnych modelu przez modyfikowanie wektora ukrytego oraz wizualizację przestrzeni ukrytej.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a6d23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = AutoEncoderAnalyzer(model=ae_model, dataset=val_dataset, n_samplings=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c33eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer.compare_reconstruction_with_original()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24973c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer.average_points_per_class()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e5ef71",
   "metadata": {},
   "outputs": [],
   "source": [
    "for digit, latent_code in enumerate(analyzer._averages):\n",
    "    print(f\"Digit: {digit}\")\n",
    "    analyzer.analyze_features(latent_code, steps=11)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cde641d",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer.analyze_tsne()  # this may take quite a long time\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e226d2",
   "metadata": {},
   "source": [
    "Do wytrenowania modelu VAE wykorzystamy bibliotekę Pyro. Funkcja ta dostarcza gotową implementację funkcji kosztu ELBO oraz metody SVI wykorzystywanej do trenowania modelu. Detale implementacyjne znajdują się w przygotowanej funkcji `train_ae`, którą wykorzystywaliśmy też wcześniej do trenowania modelu autokodera. Pyro wymaga od nas przygotowania funkcji `model` oraz `guide`. Pierwszy z nich ma definiować model generatywny $p_\\theta(\\mathbf{x} | \\mathbf{z})p_\\theta(\\mathbf{z})$, drugi natomiast odpowiada za definicję aproksymacji posteriora $q_\\phi(\\mathbf{z} | \\mathbf{x})$. Z nimi możemy wykorzystać klasę `Trace_ELBO`, która posłuży jako funkcja kosztu. Zachęcamy do zapoznania się z [dokumentacją](https://pyro.ai/examples/svi_part_i.html), gdzie znajduje się więcej informacji na temat `model`u oraz `guide`'a w bibliotece Pyro.\n",
    "\n",
    "# Zadanie 1a (1.5 pkt.)\n",
    "\n",
    "Wzorując się na implementacji klasycznego autokodera, zaimplementuj model autokodera wariacyjnego:\n",
    "\n",
    "1. Przygotuj lub wykorzystaj już przygotowane implementacje kodera oraz dekodera:\n",
    "    * Zadaniem kodera jest przetworzenie wejścia (obrazu) do parametrów rozkładu (w przypadku rozkładu normalnego: średniej i wariancji). Najczęściej parametry te tworzy się w ostatniej warstwie, używając wspólnych wcześniejszych warstw. Zwróć uwagę na zastosowanie odpowiednich funkcji aktywacji: tak, aby nie ograniczać niepotrzebnie zakresu wartości, ale również by nie uzyskać wartości nieprawidłowych.\n",
    "    * Zadaniem dekodera jest przetworzenie ukrytej reprezentacji (próbki z rozkładu) w celu wygenerowania rekonstrukcji. Zakładamy, że próbkowanie odbywa się **poza** dekoderem. Zastosuj odpowiednią funkcję aktywacji na wyjściu, tak aby uzyskać wartości o odpowiednim zakresie.\n",
    "2. Zaimplementuj klasę `VariationalAutoencoder`:\n",
    "    * Zaimplementuj metodę `encoder_forward`, która dla danego wejścia wygeneruje jego ukrytą reprezentację. Wykorzystaj parametry rozkładu generowane przez koder oraz wykonaj w tej funkcji próbkowanie.\n",
    "    * Zaimplementuj metodę `decoder_forward`, która dla danej ukrytej reprezentacji (wypróbkowanej z rozkładu) wygeneruje jego rekonstrukcję.\n",
    "\n",
    "Zwróć uwagę, że w analizach doszło porównanie kilku próbek z rozkładu ukrytego modelu.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2edaf137",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0290e8e8893797e6fdd4f1c98c60d442",
     "grade": false,
     "grade_id": "vae-research",
     "locked": true,
     "points": 1.5,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "# Zadanie 1b (1.5 pkt.)\n",
    "\n",
    "Zbadaj wpływ hiperparametrów modelu wariacyjnego autokodera (akie jak liczba neuronów w warstwach ukrytych, rozmiar ukrytej reprezentacji, współczynnik uczenia, itp.) na proces jego trenowania (szybkość, zdolność do wytrenowania, szybkość zbiegania itd.), uzyskiwane rezultaty oraz zdolności generatywne i właściwości przestrzeni ukrytej. Wykorzystaj przygotowaną klasę `AutoEncoderAnalyzer`. Zapisz wnioski w komórce Markdown.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70174f0f",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a32152286f788c8696f1646c7ce6eabf",
     "grade": true,
     "grade_id": "vae-implementation",
     "locked": false,
     "points": 1.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class VEncoder(nn.Module):\n",
    "    \"\"\"Encoder for VAE.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_input_features: int,\n",
    "        n_hidden_neurons: int,\n",
    "        n_latent_features: int,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        :param n_input_features: number of input features (28 x 28 = 784 for MNIST)\n",
    "        :param n_hidden_neurons: number of neurons in hidden FC layer\n",
    "        :param n_latent_features: size of the latent vector\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # TU WPISZ KOD\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"Encode data to gaussian distribution params.\"\"\"\n",
    "        z_loc = None\n",
    "        z_scale = None\n",
    "        # TU WPISZ KOD\n",
    "        raise NotImplementedError()\n",
    "        return z_loc, z_scale\n",
    "    \n",
    "\n",
    "class VDecoder(nn.Module):\n",
    "    \"\"\"Decoder for VAE.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_latent_features: int, \n",
    "        n_hidden_neurons: int, \n",
    "        n_output_features: int,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        :param n_latent_features: number of latent features (same as in Encoder)\n",
    "        :param n_hidden_neurons: number of neurons in hidden FC layer\n",
    "        :param n_output_features: size of the output vector (28 x 28 = 784 for MNIST)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # TU WPISZ KOD\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def forward(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Decode latent vector to image.\"\"\"\n",
    "        r = None\n",
    "        # TU WPISZ KOD\n",
    "        raise NotImplementedError()\n",
    "        return r\n",
    "\n",
    "\n",
    "class VariationalAutoencoder(BaseAutoEncoder):\n",
    "    \"\"\"Variational Auto Encoder model.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_data_features: int,\n",
    "        n_encoder_hidden_features: int,\n",
    "        n_decoder_hidden_features: int,\n",
    "        n_latent_features: int,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        :param n_data_features: number of input and output features (28 x 28 = 784 for MNIST)\n",
    "        :param n_encoder_hidden_features: number of neurons in encoder's hidden layer\n",
    "        :param n_decoder_hidden_features: number of neurons in decoder's hidden layer\n",
    "        :param n_latent_features: number of latent features\n",
    "        \"\"\"\n",
    "        encoder = VEncoder(\n",
    "            n_input_features=n_data_features,\n",
    "            n_hidden_neurons=n_encoder_hidden_features,\n",
    "            n_latent_features=n_latent_features,\n",
    "        )\n",
    "        decoder = VDecoder(\n",
    "            n_latent_features=n_latent_features,\n",
    "            n_hidden_neurons=n_decoder_hidden_features,\n",
    "            n_output_features=n_data_features,\n",
    "        )\n",
    "        super().__init__(\n",
    "            encoder=encoder, decoder=decoder, n_latent_features=n_latent_features\n",
    "        )\n",
    "        self.input_shape = None\n",
    "\n",
    "    def encoder_forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Function to perform forward pass through encoder network.\n",
    "        takes: tensor of shape [batch_size x [image-size]] (input images batch)\n",
    "        returns: tensor of shape [batch_size x latent_feature_size] (latent vector)\n",
    "        \"\"\"\n",
    "        z = None\n",
    "        if self.input_shape is None:\n",
    "            self.input_shape = x.shape[1:]\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        # TU WPISZ KOD\n",
    "        raise NotImplementedError()\n",
    "        return z\n",
    "\n",
    "    def decoder_forward(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Function to perform forward pass through decoder network.\n",
    "        takes: tensor of shape [batch_size x latent_feature_size] (latent vector)\n",
    "        returns: tensor of shape [batch_size x [image-size]] (reconstructed images batch)\n",
    "        \"\"\"\n",
    "        r = None\n",
    "        # TU WPISZ KOD\n",
    "        raise NotImplementedError()\n",
    "        return r.view(-1, *self.input_shape)\n",
    "\n",
    "    def model(self, x: torch.Tensor):\n",
    "        \"\"\"Pyro model for VAE; p(x|z)p(z).\"\"\"\n",
    "        pyro.module(\"decoder\", self.decoder)\n",
    "        with pyro.plate(\"data\", x.shape[0]):\n",
    "            z_loc = torch.zeros((x.shape[0], self.n_latent_features))\n",
    "            z_scale = torch.ones((x.shape[0], self.n_latent_features))\n",
    "            z = pyro.sample(\"latent\", dist.Normal(z_loc, z_scale).to_event(1))\n",
    "            output = self.decoder.forward(z).view(-1, *self.input_shape)\n",
    "            pyro.sample(\"obs\", dist.Bernoulli(output).to_event(3), obs=x)\n",
    "\n",
    "    def guide(self, x: torch.Tensor):\n",
    "        \"\"\"Pyro guide for VAE; q(z|x)\"\"\"\n",
    "        pyro.module(\"encoder\", self.encoder)\n",
    "        with pyro.plate(\"data\", x.shape[0]):\n",
    "            z_loc, z_scale = self.encoder.forward(x.view(x.shape[0], -1))\n",
    "            pyro.sample(\"latent\", dist.Normal(z_loc, z_scale).to_event(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d118001",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "lr = 1e-3\n",
    "epochs = 20\n",
    "\n",
    "vae_model = VariationalAutoencoder(\n",
    "    n_data_features=28 * 28,  # MNIST pixels\n",
    "    n_encoder_hidden_features=128,  # chosen arbitrarily\n",
    "    n_decoder_hidden_features=128,  # chosen arbitrarily\n",
    "    n_latent_features=10,  # how many features will be used to represent input\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, batch_size=batch_size, shuffle=False, drop_last=False\n",
    ")\n",
    "\n",
    "loss_fn = pyro.infer.Trace_ELBO().differentiable_loss\n",
    "loss_fn_args = (vae_model.model, vae_model.guide)\n",
    "\n",
    "train_ae(\n",
    "    vae_model,\n",
    "    epochs=epochs,\n",
    "    train_loader=train_dataloader,\n",
    "    val_loader=val_loader,\n",
    "    lr=lr,\n",
    "    loss_fn=loss_fn,\n",
    "    loss_fn_args=loss_fn_args,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fe53e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = AutoEncoderAnalyzer(model=vae_model, dataset=val_dataset, n_samplings=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e14665",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer.compare_reconstruction_with_original()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99b998c",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer.compare_samplings()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90392b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer.average_points_per_class()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4468b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "for digit, latent_code in enumerate(analyzer._averages):\n",
    "    print(f\"Digit: {digit}\")\n",
    "    analyzer.analyze_features(latent_code, steps=11)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcb8a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer.analyze_tsne()  # this may take quite a long time\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93ca6ed",
   "metadata": {},
   "source": [
    "# Zadanie 2 (2 pkt.)\n",
    "\n",
    "Metody uczenia reprezentacji, do których można zaliczyć autokoder wariacyjny, są często sprawdzane pod względem możliwości ich zastosowania w tzw. *downstream tasks*, czyli prostych zadaniach mających na celu weryfikację jakości utworzonej reprezentacji danych. Polegają one np. na wytrenowaniu modelu do jakiegoś zadania nie na danych, ale na ich reprezentacji, wytworzonej przez model uczenia reprezentacji. W tym przypadku tym zadaniem będzie klasyfikacja cyfr.\n",
    "\n",
    "Wybierz dowolny klasyfikator (ważne: klasyfikator ten powinien osiągać **słabe** rezultaty dla zbioru MNIST). Zbadaj, jakie wartości metryk osiąga on przy zastosowaniu wprost na danych ze zbioru MNIST; sprawdź także ile czasu zajmuje trenowanie klasyfikatora oraz wnioskowanie.\n",
    "\n",
    "Następnie zastosuj ten sam klasyfikator na ukrytych reprezentacjach wytworzonych przez oba modele autokodera: `Autoencoder` oraz `VariationalAutoencoder`, wytrenowane wcześniej (odpowiednio `ae_model` oraz `vae_model`). Przetwórz cały zbiór treningowy i walidacyjny z użyciem kodera w celu uzyskania ukrytych reprezentacji przykładów, a następnie wykorzystaj je do wytrenowania prostego klasyfikatora. Porównaj uzyskane metryki oraz szybkość działania.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03476e7",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c088d0c44f5a2ae18b0819489a895c04",
     "grade": true,
     "grade_id": "downstream-implementation",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "X_train, y_train = zip(*train_dataset)\n",
    "X_train = torch.stack(X_train)\n",
    "X_val, y_val = zip(*val_dataset)\n",
    "X_val = torch.stack(X_val)\n",
    "\n",
    "\n",
    "# TU WPISZ KOD\n",
    "raise NotImplementedError()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bd5bb3",
   "metadata": {},
   "source": [
    "# Zadanie 3 (dodatkowe) (2 pkt.)\n",
    "\n",
    "Jednym z fundamentalnych celów uczenia reprezentacji jest dążenie do uzyskania rozłącznych cech (co oznacza, że zmiana pojedynczego elementu wektora ukrytego spowoduje zmianę tylko jednej cechy obrazu wyjściowego). Poprzednie modele nie są w stanie uzyskać tego rezultatu - zmiana pojedynczego elementu wektora wpływa zazwyczaj na więcej niż jedną cechę obrazu wyjściowego.\n",
    "\n",
    "Jedno z rozwiązań pozwalające na uzyskanie rozłącznych cech jest $\\beta$-VAE. Zaproponowana modyfikacja polega na wprowadzeniu współczynnika regularyzacji $\\beta$ do funkcji kosztu, dzięki któremu możemy regulować wpływ regularyzacji aproksymacji posteriora na rezultaty trenowania:\n",
    "\n",
    "$$\\log p_\\theta \\left(\\mathbf{x}\\right) \\ge  \\mathcal{L}\\left(\\mathbf{x}, \\theta, \\phi, \\beta\\right) = \\underbrace{\\mathbb{E}_{\\mathbf{z}}\\left[\\log p_\\theta\\left(\\mathbf{x} | \\mathbf{z}\\right)\\right]}_{\\text{błąd rekonstrukcji}} - \\overbrace{\\beta}^{\\text{współczynnik regularyzacji}}\\underbrace{\\left(D_{KL}\\left(q_\\phi\\left(\\mathbf{z} | \\mathbf{x}\\right)\\| p\\left(\\mathbf{z}\\right)\\right)\\right)}_{\\text{regularyzacja aproksymacji posteriora}}.$$\n",
    "\n",
    "Publikacja: [link](https://openreview.net/references/pdf?id=Sy2fzU9gl)\n",
    "\n",
    "Zadanie polega na implementacji modelu $\\beta$-VAE. Wykorzystaj jak najwięcej komponentów klasy `VariationalAutoencoder`. Podpowiedź: należy zmodyfikować `model` oraz `guide`, wykorzystując narzędzia modyfikujące obliczanie score'ów (*effect handlers*) w Pyro: [Poutine](https://docs.pyro.ai/en/stable/poutine.html).  Przeanalizuj model z użyciem `AutoEncoderAnalyzer` - w szczególności pod względem uzyskiwanej reprezentacji ukrytej, zdolności generatywnych oraz wpływu zmian współczynnika $\\beta$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd5ab53",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "53318e6a7ea12729de4752b48e8fa897",
     "grade": true,
     "grade_id": "beta-vae",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class BetaVariationalAutoencoder(VariationalAutoencoder):\n",
    "    \"\"\"beta-Variational Auto Encoder model.\"\"\"\n",
    "    \n",
    "    # TU WPISZ KOD\n",
    "    raise NotImplementedError()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1b1cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "lr = 1e-3\n",
    "epochs = 20\n",
    "\n",
    "bvae_model = BetaVariationalAutoencoder(\n",
    "    n_data_features=28 * 28,  # MNIST pixels\n",
    "    n_encoder_hidden_features=128,  # chosen arbitrarily\n",
    "    n_decoder_hidden_features=128,  # chosen arbitrarily\n",
    "    n_latent_features=10,  # how many features will be used to represent input\n",
    "    beta=3.  # should limit the number of valuable features\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, batch_size=batch_size, shuffle=False, drop_last=False\n",
    ")\n",
    "\n",
    "loss_fn = pyro.infer.Trace_ELBO().differentiable_loss\n",
    "loss_fn_args = (bvae_model.model, bvae_model.guide)\n",
    "\n",
    "train_ae(\n",
    "    bvae_model,\n",
    "    epochs=epochs,\n",
    "    train_loader=train_dataloader,\n",
    "    val_loader=val_loader,\n",
    "    lr=lr,\n",
    "    loss_fn=loss_fn,\n",
    "    loss_fn_args=loss_fn_args,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff1d881",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = AutoEncoderAnalyzer(model=bvae_model, dataset=val_dataset, n_samplings=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda7e120",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer.compare_reconstruction_with_original()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5a12d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer.compare_samplings()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d79dcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer.average_points_per_class()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6151d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "for digit, latent_code in enumerate(analyzer._averages):\n",
    "    print(f\"Digit: {digit}\")\n",
    "    analyzer.analyze_features(latent_code, steps=11)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88865d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer.analyze_tsne()  # this may take quite a long time\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
